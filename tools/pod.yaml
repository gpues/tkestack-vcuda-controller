apiVersion: v1
kind: Pod
metadata:
  name: gpu-pod1
spec:
  containers:
    - name: tf
      image: registry.cn-hangzhou.aliyuncs.com/acejilam/tensorflow:2.14.0-gpu
      command: [ "bash", "-c", "sleep 1d" ]
      resources:
        limits:
#          nvidia.com/mig-3g.20gb: 1 # requesting 2 vGPUs
          nvidia.com/gpu: 2 # requesting 2 vGPUs
          nvidia.com/gpumem: 3000
          # nvidia.com/gpumem-percentage: 50 # Each vGPU contains 100% of the entire GPU device memory （Optional,Integer）
          nvidia.com/gpucores: 30 # Each vGPU uses 30% of the entire GPU cores（Optional,Integer)
      volumeMounts:
        - name: x
          mountPath: /data
  volumes:
    - name: x
      hostPath:
        path: /root/hook/tools
# helm uninstall vgpu -n kube-system
# helm install vgpu vgpu-charts/vgpu --set scheduler.kubeScheduler.imageTag=v1.25.5 --set devicePlugin.deviceMemoryScaling=5 --set devicePlugin.image=acejilam/k8s-vdevice -n kube-system


# docker run --rm -it -v /usr/local/vgpu/ld.so.preload:/etc/ld.so.preload -v /root/hook/test/libvgpu.so:/usr/local/vgpu/libvgpu.so registry.cn-hangzhou.aliyuncs.com/acejilam/tensorflow:2.14.0-gpu bash
# docker run --rm -it -v `pwd`:/data -v /usr/local/vgpu/ld.so.preload:/etc/ld.so.preload -v /root/hook/test/libvgpu.so:/usr/local/vgpu/libvgpu.so registry.cn-hangzhou.aliyuncs.com/acejilam/tensorflow:2.14.0-gpu python3 /data/tools/cifar10_train.py



